import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from pinecone import Pinecone
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from ai_functions import categorize_content, extract_articles_from_docs, format_documents
import cohere

load_dotenv()
PINECONE_INDEX_NAME = "better-rag-index"
COHERE_API_KEY = os.getenv("COHERE_API_KEY")

def get_llm(model = "gpt-4o-mini"):
    llm = ChatOpenAI(model = model)
    return llm

def get_dictionary_chain(llm):
    # 3. í‚¤ì›Œë“œ ì‚¬ì „ í™œìš©
    keyword_dict  = [
        "ì‚¬ëŒì„ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„ -> ê±°ì£¼ì",
        "ì§ì¥ì¸ -> ê·¼ë¡œì†Œë“ì´ ìˆëŠ” ê±°ì£¼ì", 
        "ì›”ê¸‰ìŸì´ -> ê·¼ë¡œì†Œë“ì´ ìˆëŠ” ê±°ì£¼ì",
        "íšŒì‚¬ì› -> ê·¼ë¡œì†Œë“ì´ ìˆëŠ” ê±°ì£¼ì",
        "ì—°ë´‰ -> ì¢…í•©ì†Œë“",
        "ì›”ê¸‰ -> ê·¼ë¡œì†Œë“",
        "ì„¸ê¸ˆ -> ì†Œë“ì„¸",
        "ê³µì œë°›ë‹¤ -> ê³µì œë¥¼ ì ìš©ë°›ë‹¤",
        "ì–¼ë§ˆë‚˜ ë‚´ì•¼í•˜ë‚˜ -> ì„¸ì•¡ì€ ì–¼ë§ˆì¸ê°€",
        "ê³„ì‚°í•´ì¤˜ -> ê³„ì‚°í•˜ë©´ ì–¼ë§ˆì¸ê°€"
    ]
    prompt = ChatPromptTemplate.from_template(f"""ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³´ê³ , ìš°ë¦¬ì˜ ì‚¬ì „ì„ ì°¸ê³ í•´ì„œ 
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•´ ì£¼ì„¸ìš”. ë§Œì•½ ë³€ê²½í•  í•„ìš”ê°€ ì—†ì„ê²½ìš°, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
    ê·¸ëŸ° ê²½ìš°ì—ëŠ” ì§ˆë¬¸ë§Œ ë¦¬í„´í•´ ì£¼ì„¸ìš”.
    ì‚¬ì „ : {keyword_dict}
    ì§ˆë¬¸ : {{question}}""")
    keyword_chain = prompt | llm | StrOutputParser()
    return keyword_chain

def get_retriever(normalized_query, model="text-embedding-3-large", k=15):
    # Retriever ìƒì„±    
    embedding = OpenAIEmbeddings(model=model)
    vector_database = PineconeVectorStore(
        embedding=embedding,  # ì§ˆë¬¸ì„ ì„ë² ë”©í•˜ì—¬ ìœ ì‚¬ë„ ê²€ìƒ‰
        index_name=PINECONE_INDEX_NAME
    )
    filter_condition = {"category": {"$in": categorize_content(normalized_query)}}
    retriever = vector_database.as_retriever(
        search_type="similarity",
        search_kwargs={"k": k, "filter": filter_condition}
    )
    return retriever

def rerank_by_title(query: str, documents: list, top_k: int = 4) -> list:
    """
    Cohereì˜ Rerank APIë¥¼ ì‚¬ìš©í•œ ë¬¸ì„œ ì¬ì •ë ¬
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        documents: ê²€ìƒ‰ëœ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
        top_k: ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜ (ê¸°ë³¸ê°’ì€ 4)    
    Returns:
        list: title ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ì¬ì •ë ¬ëœ Document ë¦¬ìŠ¤íŠ¸
    """
    # Cohere í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    co = cohere.Client(api_key=COHERE_API_KEY)
    # Document ê°ì²´ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë­ titleì´ ìˆìœ¼ë‹ˆ titleë„ í¬í•¨í•¨)
    docs_text = [doc.metadata.get('title', '') +" "+doc.page_content for doc in documents]
    # docs_text = [doc.page_content for doc in documents]
    # Cohere Rerank API í˜¸ì¶œ
    results = co.rerank(
        model="rerank-multilingual-v3.0",  # í•œêµ­ì–´ ì§€ì› ëª¨ë¸
        query=query,
        documents=docs_text,
        top_n=top_k,
        # return_documents=False  # ë¬¸ì„œ ë‚´ìš©ì€ ë°˜í™˜í•˜ì§€ ì•ŠìŒ (ì¸ë±ìŠ¤ë§Œ)
    )    
    # ì¬ì •ë ¬ëœ ë¬¸ì„œ ë°˜í™˜
    reranked_docs = [documents[r.index] for r in results.results]
    return reranked_docs
    
def rag_chain(llm):
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    template = f"""ë‹¹ì‹ ì€ ìµœê³ ì˜ í•œêµ­ ì†Œë“ì„¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ë‹¤ìŒ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.
    ë‹µì„ ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë‹µí•˜ì„¸ìš”.
    ìµœëŒ€ 3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
    ì§ˆë¬¸ : {{query}}
    ë¬¸ë§¥ : {{context}}
    ë‹µë³€ : """
    prompt = ChatPromptTemplate.from_template(template)
    # RAG ì²´ì¸ êµ¬ì„± (LCEL ë°©ì‹)
    prompt_chain = prompt | llm  | StrOutputParser()
    return prompt_chain

#  ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ë¡œ ë§Œë“¤ê¸°
def ask_with_reference_rerank(query: str, k: int = 15, top_k:int=4, ):
    """
    ì§ˆë¬¸ì— ë‹µë³€í•˜ê³  ì°¸ì¡° ì¡°í•­ì„ í•¨ê»˜ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸
        k: ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜ (ê¸°ë³¸ê°’ 3)
    query, í‘œì¤€í™”ëœ query, ìƒì„±ëœ ë‹µë³€, ì°¸ì¡°ì¡°í•­ ì¶œë ¥
    """
    # 1. LLMê³¼ ì„ë² ë”© ì´ˆê¸°í™”
    llm = get_llm()    
    keyword_chain = get_dictionary_chain(llm=llm)
    # ì§ˆë¬¸ í‘œì¤€í™”
    normalized_query = keyword_chain.invoke({"question": query})
    # Retriever ìƒì„±
    retriever = get_retriever(normalized_query=normalized_query)
    # ë¬¸ì„œ ê²€ìƒ‰
    documents = retriever.invoke(normalized_query)
    # queryì™€ ìœ ì‚¬ë„ê°€ ë†’ì€ titleë¡œ RERANKëœ ë¬¸ì„œ ê²€ìƒ‰
    reranked_documents = rerank_by_title(query=normalized_query, documents=documents, top_k=top_k)
    # ì°¸ì¡° ì¡°í•­ ì¶”ì¶œ
    referenced_articles = extract_articles_from_docs(reranked_documents)
    prompt_chain = rag_chain(llm=llm)
    
    # 7. ì‹¤í–‰
    answer = prompt_chain.invoke({"context":format_documents(reranked_documents), 
                                "query":normalized_query})
    result = "\n\n".join([f"â˜‘ï¸ ë‹µë³€: {answer}", 
                            f"ğŸ“Œ ì°¸ì¡°: {referenced_articles}", 
                            "* ìœ„ì˜ ë‹µë³€ì€ AIì— ì˜í•´ ì‘ì„±ëœ ë‹µë³€ì´ë¯€ë¡œ ì•½ê°„ì˜ ì°¨ì´ê°€ ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤ *"])
    return result