{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee0483b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:99% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
       "div.text_cell_render.rendered_html{font-size:20pt;}\n",
       "div.text_cell_render ul li, div.text_cell_render ol li p, code{font-size:22pt; line-height:30px;}\n",
       "div.output {font-size:24pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:24pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
       "table.dataframe{font-size:24px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:99% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
    "div.text_cell_render.rendered_html{font-size:20pt;}\n",
    "div.text_cell_render ul li, div.text_cell_render ol li p, code{font-size:22pt; line-height:30px;}\n",
    "div.output {font-size:24pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:24pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
    "table.dataframe{font-size:24px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5391855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import logging\n",
    "# 경고 제거\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# transformers 로깅 레벨 조정\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Hugging Face symlink 경고 제거\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# from transformers import pipeline, logging as hf_logging\n",
    "# hf_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74e302f",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">ch1. 허깅페이스</span>\n",
    "- Inference API 이용 : 모델의 결과를 surver에서 \n",
    "- pipeline() 이용 : 모델을 다운로드받아 모델의 결과를 local에서\n",
    "    * raw text -> tokenizer -> model -> [0.11, 0.55, 0.xx, ~] logits값으로 prediction 결과 출력\n",
    "```\n",
    "허깅페이스 transformers에서 지원하는 task\n",
    "\"sentiment-analysis\" : \"text-classification\"의 별칭(감정분석 전용으로 사용)\n",
    "\"text-classification\" : 감정분석, 뉴스분류, 리뷰 분류 등 일반적인 문장 분류\n",
    "\"zero-shot-classification\" : 레이블을 학습 없이 주어진 후보군 중에서 분류\n",
    "\"token-classification\" : 개체명 인식(NER ; Named Entity REcognition) 등 단위 라벨링\n",
    "\"ner\" : \"token-classification\"의 별칭\n",
    "\"fill-mask\" : 빈칸 채우기\n",
    "\"text-generation\" : 텍스트 생성 (GPT류 모델에 사용)\n",
    "\"text2text-generation\" : 번역, 요약 등 입력 -> 출력 변환 \n",
    "\"translation\" : 번역\n",
    "\"summarization\" : 텍스트요약\n",
    "\"question-answering\" : 주어진 context를 보고 질문에 답하기.\n",
    "\"image-to-text\" : 그림을 설명\n",
    "\"image-classification\" : 이미지분류\n",
    "```\n",
    "\n",
    "## 1. 텍스트 기반 감정분석(긍정/부정)\n",
    "- c:/사용자/내컴퓨터명/.cache/huggingface/hub 모델 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0584e91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(task=\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a92c4389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(task=\"text-classification\",\n",
    "                     model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "# 감정분석시 내용이 많으면 list로\n",
    "classifier([\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e126db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8578149676322937},\n",
       " {'label': 'POSITIVE', 'score': 0.9998821020126343}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"이 영화 정말 최고였어요. 감동적이고 연기가 대단해\",\n",
    "            \"This movie was the best. It's touching, and the acting is amazing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9be7f089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8577594757080078}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"이 물건 정말 사고 싶어요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bfd2f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998695850372314},\n",
       " {'label': 'POSITIVE', 'score': 0.999488353729248},\n",
       " {'label': 'NEGATIVE', 'score': 0.5993236303329468},\n",
       " {'label': 'POSITIVE', 'score': 0.8669536709785461}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"I like you\", \"I hat you\", \"나 너가 싫어\", \"힘들어요\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "458aa5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(task=\"sentiment-analysis\",\n",
    "                     model=\"matthewburke/korean_sentiment\")\n",
    "texts = ['나는 너가 좋아', \"당신이 싫어요\", \"힘들어요\", \"오늘 기분이 최고야\"]\n",
    "result = classifier(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a9736b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 너가 좋아 => 긍정 : 0.9558\n",
      "당신이 싫어요 => 부정 : 0.9093\n",
      "힘들어요 => 부정 : 0.9140\n",
      "오늘 기분이 최고야 => 긍정 : 0.9714\n"
     ]
    }
   ],
   "source": [
    "for text, result in zip(texts, classifier(texts)):\n",
    "    label = \"긍정\" if result['label']=='LABEL_1' else \"부정\"\n",
    "    print(f\"{text} => {label} : {result['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e32aa",
   "metadata": {},
   "source": [
    "## 2. 제로샷분류(Zero-shot분류)\n",
    "- 기계학습 및 자연어처리에서 각 개별 작업에 대한 특정 교육없이 작업을 수행할 수 있는 모형(비지도학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b22763d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I have a problem with my iphone that needs to be resolved asap!',\n",
       " 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'],\n",
       " 'scores': [0.5227578282356262,\n",
       "  0.4581405818462372,\n",
       "  0.014264547266066074,\n",
       "  0.0026850118301808834,\n",
       "  0.0021520592272281647]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                     # model=\"facebook/bart-large-mnli\"\n",
    "                     )\n",
    "classifier(\n",
    "    \"I have a problem with my iphone that needs to be resolved asap!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "562eb643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'One day I well see the world',\n",
       " 'labels': ['travel', 'cooking', 'dancing'],\n",
       " 'scores': [0.9938077330589294, 0.0030999132432043552, 0.003092374885454774]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_classify = \"One day I well see the world\"\n",
    "candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68694e7",
   "metadata": {},
   "source": [
    "## 3. text 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dafff496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'in this course. We will teach you how to build your own tools to solve your own problems. We will teach you how to create code that works for you. We will teach you how to use a project manager to manage your project with ease. We will teach you how to build new tools to solve problems for you. We will teach you how to use a project manager to manage your project with ease. We will teach you how to use a project manager to manage your project with ease. We will teach you how to use a project manager to manage your project with ease.\\n\\n\\nWe will teach you how to build your own tools to solve your own problems. We will teach you how to use a project manager to manage your project with ease. We will teach you how to use a project manager to manage your project with ease. We will teach you how to build your own tools to solve your own problems. We will teach you how to use a project manager to manage your project with ease. We will teach you how to use a project manager to manage your project with ease. We will teach you how to build your own tools to solve your own problems. We will teach you how to build your own tools to solve your own problems. We will teach you how to build your own tools to solve your own problems.'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "# set_seed(2)\n",
    "generation = pipeline(\"text-generation\", \"gpt2\") # 텍스트 생성 gpt3부터는 허깅페이스없음\n",
    "generation(\n",
    "    \"in this course. We will teach you how to\",\n",
    "    pad_token_id=generation.tokenizer.eos_token_id\n",
    ") # pad_token_id 경고를 없애려고 setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f512bc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this course. We will teach you how to create virtual objects, how to use virtual controllers to implement your application, and how to create classes, functions, and properties. We will cover the basics of creating virtual objects, how to create virtual controllers, and how to use virtual services. We'll discuss the fundamentals of virtual objects and how to use services to create virtual objects. We'll also cover the various ways to use virtual services to create virtual objects and how to use virtual services. We'll discuss the concepts of virtual methods, virtual objects, and virtual virtual functions. We'll also learn how to use virtual functions to create virtual functions and how to use virtual services. We'll also learn how to use virtual functions with virtual objects. And we'll get you started on this course!\n",
      "\n",
      "Virtual Objects\n",
      "\n",
      "In this course, we'll learn how to create virtual objects, how to use virtual controllers, how to use virtual services, and how to use virtual services. We will cover the basics of creating virtual objects, how to use virtual controllers, how to use virtual services, and how to use virtual services. We'll also cover the various ways to use virtual services with virtual objects. And we'll get you started on this course!\n",
      "\n",
      "Virtual Functions\n",
      "\n",
      "In this course, we'll learn how to create\n"
     ]
    }
   ],
   "source": [
    "result = generation(\n",
    "    \"in this course. We will teach you how to\",\n",
    "    pad_token_id=generation.tokenizer.eos_token_id\n",
    ") \n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0f3872f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 과정은 다음과 같은 방법을 알려드려요. 뭘 하든 상관없으니까요.\"\n",
      "그러나 그는 그런 말을 듣고는 말을 이었다.\n",
      "\"나도 그 이야기를 들었어요.\"\n",
      "\"그런데 나는 아무것도 묻지 않았어요. 단지 나보다 더 잘 알 수 있는 사람들을 봤기 때문이에요.\"\n",
      "\"그러니까 그 사람들보다는 그 사람들의 성격이 더 좋다고 생각해요.\"\n",
      "\"그래서 그 사람은 어떤 사람이었어요?\"\n",
      "\"그렇지요. 나는 그 사람의 성격이 아주 좋았어요.\"\n",
      "\"그 사람은 아주 잘 알 수 있었어요.\"\n",
      "\"그 사람은 아주 잘 알 수 있었어요.\"\n",
      "\"그 사람은 아주 잘 알고 있었어. 하지만 그 사람은 아주 잘 알 수 있었어. 그 사람은 아주 잘 알고 있었어. 그 사람은 아주 잘 알고 있었어.\"\n",
      "\"그 사람은 아주 잘 알고 있었어. 그리고 그 사람은 아주 잘 알고 있었어.\"\n",
      "\"그 사람은 정말 잘 알고 있었어요.\"\n",
      "\"그 사람은 아주 잘 알고 있었어. 그리고 그 사람은 아주 잘 알고 있었어. 그런데 나는 그\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "generation = pipeline(\"text-generation\", \"skt/kogpt2-base-v2\")\n",
    "result = generation(\n",
    "    \"이 과정은 다음과 같은 방법을 알려드려요. \",\n",
    "    pad_token_id = generation.tokenizer.eos_token_id,\n",
    "    max_new_tokens = 200, # 생성할 최대 길이(생성할 토큰 수)\n",
    "#     num_return_sequences=1,    # 생성할 문장 갯수\n",
    "#     do_sample=True,            # 다양한 샘플 사용\n",
    "#     top_k=50,            # top-k 샘플링(확률 높은 상위 50개 토큰만 사용)         \n",
    "#     top_p=0.95,          # 확률이 높은 순서대로 95%가 될 때까지의 단어들로만 후보로 사용\n",
    "#     temperature=1.0,     # 창의성 조절(낮을 수록 보수적)\n",
    "#     no_repeat_ngram_size=2 # 반복 방지\n",
    ")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48588c16",
   "metadata": {},
   "source": [
    "## 4. 마스크(빈칸) 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b181d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.19275875389575958,\n",
       "  'token': 3299,\n",
       "  'token_str': ' doctor',\n",
       "  'sequence': \"I'm going to hospital and meet a doctor\"},\n",
       " {'score': 0.06794668734073639,\n",
       "  'token': 27321,\n",
       "  'token_str': ' psychiatrist',\n",
       "  'sequence': \"I'm going to hospital and meet a psychiatrist\"}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(task='fill-mask',\n",
    "                   model='distilbert/distilroberta-base') # 마스크 채우기\n",
    "unmasker(\"I'm going to hospital and meet a <mask>\", top_k=2) # top_k 기본값 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2f927cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unmasker(\"병원에 가서 <mask>를 만날 거예요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d8f8843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.0361194983124733,\n",
       "  'token': 265,\n",
       "  'token_str': ' business',\n",
       "  'sequence': \"Hello, I'm a business model\"},\n",
       " {'score': 0.02683814987540245,\n",
       "  'token': 18150,\n",
       "  'token_str': ' freelance',\n",
       "  'sequence': \"Hello, I'm a freelance model\"},\n",
       " {'score': 0.024143634364008904,\n",
       "  'token': 774,\n",
       "  'token_str': ' role',\n",
       "  'sequence': \"Hello, I'm a role model\"},\n",
       " {'score': 0.02224765345454216,\n",
       "  'token': 2734,\n",
       "  'token_str': ' fashion',\n",
       "  'sequence': \"Hello, I'm a fashion model\"},\n",
       " {'score': 0.0169452466070652,\n",
       "  'token': 6429,\n",
       "  'token_str': ' lady',\n",
       "  'sequence': \"Hello, I'm a lady model\"}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Hello, I'm a <mask> model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeafb3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.14130696654319763,\n",
       "  'token': 35,\n",
       "  'token_str': ':',\n",
       "  'sequence': '안녕하세요? 나는: 모델이예요.'},\n",
       " {'score': 0.1223805844783783,\n",
       "  'token': 116,\n",
       "  'token_str': '?',\n",
       "  'sequence': '안녕하세요? 나는? 모델이예요.'},\n",
       " {'score': 0.08188147097826004,\n",
       "  'token': 328,\n",
       "  'token_str': '!',\n",
       "  'sequence': '안녕하세요? 나는! 모델이예요.'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"안녕하세요? 나는 <mask> 모델이예요.\", top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da751ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b37ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f5c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eeede9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98d6cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b67f1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd82e594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3284b92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08faa67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp(ipykernel)",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
