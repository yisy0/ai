{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a6fb6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:99% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
       "div.text_cell_render.rendered_html{font-size:20pt;}\n",
       "div.text_cell_render li, div.text_cell_render p, code{font-size:22pt; line-height:40px;}\n",
       "div.output {font-size:24pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:24pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
       "table.dataframe{font-size:24px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:99% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
    "div.text_cell_render.rendered_html{font-size:20pt;}\n",
    "div.text_cell_render li, div.text_cell_render p, code{font-size:22pt; line-height:40px;}\n",
    "div.output {font-size:24pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:24pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
    "table.dataframe{font-size:24px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0371e7db",
   "metadata": {},
   "source": [
    "# 문장 -> 임베딩 벡터(1차원 숫자 배열)\n",
    "- openAI API의 키 OPENAI_API_KEY (text-embedding-3-large)를 .env에 추가\n",
    "- upstage(https://console.upstage.ai) 의 키 UPSTAGE_API_KEY를 .env에 추가\n",
    "# 1. 환경변수 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de4b6968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n",
      "up\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\n",
    "   # dotenv_path='.env'\n",
    ")\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "upstage_key = os.getenv('UPSTAGE_API_KEY')\n",
    "print(openai_key[:2])\n",
    "print(upstage_key[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96743a9",
   "metadata": {},
   "source": [
    "# 2. 유사도 계산하는 방법\n",
    "- 1. 유클리드 거리 : 두 벡터간 거리가 가까운지\n",
    "- 2. 코사인 유사도 : 두 벡터간 방향이 유사한지\n",
    "- 3. dot product : 두 벡터간 곱을 사용하여 거리와 방향을 모두 고려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33de6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"두 백터 사이의 코사인 유사도 계산\"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1) \n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    if norm_vec1==0 or norm_vec2==0:\n",
    "        return 0.0\n",
    "    return dot_product / (norm_vec1*norm_vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa9ea33",
   "metadata": {},
   "source": [
    "# 3. openAI API의 embedding model 사용\n",
    "- text-embedding-3-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f2b7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai_client = OpenAI(\n",
    "    # api_key=openai_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ba38239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text-embedding-3-large(과금)\n",
    "response = openai_client.embeddings.create(\n",
    "    input= \"The king is the prince's father\",\n",
    "    model=\"text-embedding-3-large\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e91f45af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(prompt_tokens=7, total_tokens=7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d80c8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072,)\n",
      "[ 0.03370763  0.03378944 -0.00436004 ...  0.01654019  0.01049273\n",
      " -0.00589065]\n"
     ]
    }
   ],
   "source": [
    "king_vector = np.array(response.data[0].embedding) # The king is ~ 문장을 숫자로 바꾼 vec\n",
    "print(king_vector.shape)\n",
    "print(king_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8c2b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_response = openai_client.embeddings.create(\n",
    "    input=\"The queen is the prince's mother\",\n",
    "    model=\"text-embedding-3-large\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6969df3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(prompt_tokens=7, total_tokens=7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queen_response.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f41445a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072,)\n",
      "[ 0.01908419  0.00117847 -0.00398764 ...  0.00576628  0.00822409\n",
      "  0.01082648]\n"
     ]
    }
   ],
   "source": [
    "queen_vector = np.array(queen_response.data[0].embedding)\n",
    "print(queen_vector.shape)\n",
    "print(queen_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "923c4066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king문장과 queen문장의 유사도 : 0.6953489600831544\n"
     ]
    }
   ],
   "source": [
    "# king_vector와 queen_vector의 유사도\n",
    "king_queen_similarity = cosine_similarity(king_vector, queen_vector)\n",
    "print(\"king문장과 queen문장의 유사도 :\", king_queen_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78c78d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_response = openai_client.embeddings.create(\n",
    "    input = \"The slave begs\",\n",
    "    model=\"text-embedding-3-large\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c08caea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072,)\n",
      "[-0.00868506  0.00686     0.00754387 ... -0.00823628 -0.0112752\n",
      "  0.00194153]\n"
     ]
    }
   ],
   "source": [
    "slave_vector = np.array(slave_response.data[0].embedding)\n",
    "print(slave_vector.shape)\n",
    "print(slave_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "378c78f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king문장과 slave문장 유사도 : 0.18331621342902388\n"
     ]
    }
   ],
   "source": [
    "king_slave_similarity = cosine_similarity(king_vector, slave_vector)\n",
    "print(\"king문장과 slave문장 유사도 :\", king_slave_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa56f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 문장을 벡터로 바꿔도 유사도가 비슷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d026a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.embeddings.create(\n",
    "    input=\"왕은 왕자의 아버지다\",\n",
    "    model=\"text-embedding-3-large\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e27f55f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072,)\n",
      "[0.01460524 0.0081415  0.00299669 ... 0.00721534 0.01149217 0.00849063]\n"
     ]
    }
   ],
   "source": [
    "kor_king_vector = np.array(response.data[0].embedding)\n",
    "print(kor_king_vector.shape)\n",
    "print(kor_king_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59424d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.embeddings.create(\n",
    "    input=\"여왕은 왕자의 어머니다\",\n",
    "    model=\"text-embedding-3-large\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "838d2990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00633463  0.01295298  0.00534164 ... -0.00638844 -0.00050108\n",
      "  0.0337521 ]\n"
     ]
    }
   ],
   "source": [
    "kor_queen_vector = np.array(response.data[0].embedding)\n",
    "print(kor_queen_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f15f312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "왕문장과 여왕문장의 유사도 : 0.5744286874279492\n"
     ]
    }
   ],
   "source": [
    "print(\"왕문장과 여왕문장의 유사도 :\", cosine_similarity(kor_king_vector, kor_queen_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c1c937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.embeddings.create(\n",
    "    input=\"노예가 구걸한다\",\n",
    "    model=\"text-embedding-3-large\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78c990d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00524604  0.0030029   0.00265426 ... -0.01131434 -0.00262631\n",
      "  0.01126829]\n"
     ]
    }
   ],
   "source": [
    "kor_slave_vector = np.array(response.data[0].embedding)\n",
    "print(kor_slave_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cedf8255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "왕문장과 노예문장의 유사도 : 0.13567770295253703\n"
     ]
    }
   ],
   "source": [
    "print(\"왕문장과 노예문장의 유사도 :\", cosine_similarity(kor_king_vector, kor_slave_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17696391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king문장과 왕문장의 유사도 : 0.6248509347773605\n"
     ]
    }
   ],
   "source": [
    "# king_vector와 kor_king_vector의 유사도\n",
    "print(\"king문장과 왕문장의 유사도 :\", cosine_similarity(king_vector, kor_king_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d086e75",
   "metadata": {},
   "source": [
    "# 4. upstage의 embedding model 사용\n",
    "- 한국어에서는 openai 보다 성능이 좋다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5744631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "upstage_client = OpenAI(\n",
    "    api_key=upstage_key,\n",
    "    base_url=\"https://api.upstage.ai/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2635607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = upstage_client.embeddings.create(\n",
    "    input=\"The king is prince's father\",\n",
    "    model=\"embedding-query\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8561ca6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096,)\n",
      "[ 6.99263182e-05 -3.04292757e-02 -2.85108201e-03 ... -7.22163310e-03\n",
      "  1.04733631e-02  3.70790288e-02]\n"
     ]
    }
   ],
   "source": [
    "up_king_vector = np.array(response.data[0].embedding)\n",
    "print(up_king_vector.shape)\n",
    "print(up_king_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bdab1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = upstage_client.embeddings.create(\n",
    "    input=\"The queen is prince's mother\",\n",
    "    model=\"embedding-query\"\n",
    ")\n",
    "up_queen_vector = np.array(response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92add183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king문장과 queen문장의 유사도 : 0.6694549910572132\n"
     ]
    }
   ],
   "source": [
    "print(\"king문장과 queen문장의 유사도 :\", cosine_similarity(up_king_vector, up_queen_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "624eda76",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = upstage_client.embeddings.create(\n",
    "    input=\"왕은 왕자의 아버지다\",\n",
    "    model=\"embedding-query\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ede5d6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096,)\n"
     ]
    }
   ],
   "source": [
    "up_kor_king_vector = np.array(response.data[0].embedding)\n",
    "print(up_kor_king_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796f6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = upstage_client.embeddings.create(\n",
    "    input=\"여왕은 왕자의 어머니다\",\n",
    "    model=\"embedding-query\"\n",
    ")\n",
    "up_kor_queen_vector = np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb799b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55b608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b294c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
