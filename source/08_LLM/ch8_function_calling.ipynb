{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eb39f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:99% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
       "div.text_cell_render.rendered_html{font-size:20pt;}\n",
       "div.text_cell_render li, div.text_cell_render p, code{font-size:22pt; line-height:40px;}\n",
       "div.output {font-size:24pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:24pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
       "table.dataframe{font-size:24px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:99% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
    "div.text_cell_render.rendered_html{font-size:20pt;}\n",
    "div.text_cell_render li, div.text_cell_render p, code{font-size:22pt; line-height:40px;}\n",
    "div.output {font-size:24pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:24pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
    "table.dataframe{font-size:24px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68634886",
   "metadata": {},
   "source": [
    "# OpenAI API function calling 기능 실습 (2025년 3월 기준)\n",
    "\n",
    "본 실습에서는 OpenAI Assistants API의 **함수 호출(Function Calling)** 기능을 사용하여, AI 어시스턴트가 외부 함수를 호출하고 그 결과를 응답에 활용하는 방법을 단계별로 살펴보겠습니다. 2025년 3월 기준의 OpenAI 공식 API 문서를 바탕으로 최신 함수 호출 기능과 모범 사례를 반영하여 진행합니다. 이 실습은 기존에 ChatGPT API 등을 사용해본 경험이 있고, Assistants API의 새로운 함수 호출 기능에 관심이 있는 개발자를 대상으로 합니다.\n",
    "\n",
    "## 1. 함수 호출 기능 소개\n",
    "\n",
    "함수 호출 기능은 모델이 사전에 정의된 함수를 필요에 따라 실행하도록 도와주는 강력한 도구입니다. 이 기능을 통해 어시스턴트는 자체 지식에 없는 **실시간 정보 조회**나 **복잡한 계산 작업** 등을 외부 함수에 위임할 수 있습니다. 예를 들어 사용자가 날씨를 물어보면, 어시스턴트는 날씨 API와 연결된 함수를 호출하여 최신 기온을 가져온 뒤 응답할 수 있습니다. 이처럼 함수 호출을 활용하면:\n",
    "- **실시간/외부 데이터 활용:** 모델이 최신 정보(날씨, 주가, 뉴스 등)를 함수로부터 받아와 답변에 반영할 수 있습니다.\n",
    "- **모델 한계 보완:** 수학 계산, 데이터베이스 질의 등 모델이 직접 처리하기 어려운 요청을 외부 로직으로 해결할 수 있습니다.\n",
    "- **도메인 확장:** 개발자가 정의한 임의의 함수로 모델의 기능을 확장할 수 있어, 특정 분야나 서비스에 특화된 어시스턴트를 구현할 수 있습니다.\n",
    "\n",
    "OpenAI의 GPT-3.5/4 모델 중 2023년 하반기 이후 출시된 버전들은 이 함수 호출 기능을 지원합니다. 모델에게 함수 목록을 제공하면, 질문 의도에 따라 적절한 함수를 선택해 필요한 인수를 함께 호출 형식으로 응답을 반환합니다. 이제 이러한 함수 호출을 구현하는 방법을 예제로 알아보겠습니다.\n",
    "\n",
    "## 2. API 키 설정 및 OpenAI 클라이언트 초기화\n",
    "\n",
    "OpenAI API를 사용하기 위해 먼저 API 키를 준비해야 합니다. API 키는 OpenAI 계정의 대시보드에서 생성할 수 있으며, 노출되지 않도록 환경 변수 등에 저장하여 사용합니다. 본 예제에서는 **python-dotenv**를 이용해 `.env` 파일에 저장된 키를 로드하고, OpenAI Python SDK의 `OpenAI` 클라이언트를 초기화합니다. \n",
    "아래 코드에서는 `.env` 파일에서 키를 읽어와 `client = OpenAI()`로 클라이언트를 생성합니다. (API 키가 올바르게 설정되어 있으면 `OpenAI()` 생성자에서 자동으로 키를 불러옵니다.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3e6f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from decouple import config\n",
    "from openai import OpenAI\n",
    "import os\n",
    "# 1. client 생성\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ac040",
   "metadata": {},
   "source": [
    "## 3. 외부 함수 정의 및 테스트\n",
    "\n",
    "이제 함수 호출 기능을 체험하기 위한 예시로 **날씨 정보를 가져오는 함수**를 만들어보겠습니다. 사용자가 \"서울 날씨 어때요?\"라고 물어보면, 어시스턴트가 이 함수를 호출하여 실시간 날씨 정보를 얻어 답변하도록 해볼 것입니다. \n",
    "\n",
    "예를 위해 간단한 `get_weather` 함수를 정의하겠습니다. 이 함수는 위도(latitude)와 경도(longitude)를 받아 해당 위치의 현재 기온을 섭씨로 반환합니다. 구현에는 오픈 메테오(Open-Meteo)라는 공개 기상 API를 사용하여, 주어진 좌표의 현재 기온 데이터를 가져옵니다. 함수는 `requests` 라이브러리를 통해 API를 호출하고, 응답 JSON에서 온도 값을 추출하여 반환합니다. \n",
    "\n",
    "함수를 정의한 후, 예시 좌표에 대해 함수를 호출해 제대로 동작하는지 확인해 보겠습니다. 서울의 대략적인 좌표(위도 37.484859, 경도 126.930086)를 입력으로 주었을 때 온도가 잘 반환되는지 출력해 보겠습니다.\n",
    "def get_weather(latitude=37.484859, longitude=126.930086):\n",
    "    url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m\"\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95f18d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 37.484642, 126.930063\n",
    "import requests\n",
    "import json\n",
    "def get_weather(latitude=37.484642, longitude=126.930063):\n",
    "    url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m\"\n",
    "    # print(url)\n",
    "    response = requests.get(url)\n",
    "    # data = json.loads(response.text)\n",
    "    data = response.json()\n",
    "    current = data.get('current')\n",
    "    if current is not None:\n",
    "        return current.get('temperature_2m')\n",
    "    else:\n",
    "        return None\n",
    "get_weather(37.484, 126.930063)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6816beb3",
   "metadata": {},
   "source": [
    "## 4. 함수 툴 설정 및 모델 응답 생성\n",
    "\n",
    "이제 OpenAI API에 우리가 정의한 함수를 **툴(tool)**로 등록하고, 모델이 이 함수를 호출하도록 유도해 보겠습니다. \n",
    "이를 위해 먼저 `tools`라는 리스트에 함수 정보를 구성합니다. 각 함수 툴에는 이름(name), 설명(description), 그리고 매개변수(parameters) 스키마를 지정해야 합니다. 아래 코드에서는 `type`: \"function\"으로 함수를 정의하고, `name`: \"get_weather\", `description`: \"저장된 좌표의 현재 온도를 섭씨 단위로 구합니다\"와 같이 설정했습니다. 또한 `parameters` 필드에 함수가 요구하는 인자들의 JSON 스키마(여기서는 latitude와 longitude 숫자형, 둘 다 필수)를 명시했습니다. \n",
    "\n",
    "그 다음 어시스턴트에게 보낼 `messages`를 준비합니다. 사용자의 질문으로 \"오늘 서울 날씨 어때요?\"라는 메시지를 추가하겠습니다. 이제 이 사용자 메시지와 함께 `client.chat.completions.create`를 호출하여, 모델의 응답을 받아보겠습니다. `tools` 파라미터에 앞서 정의한 함수 정보를 포함시켰으므로, 모델은 답변 과정에서 이 함수를 호출할 수 있게 됩니다.\n",
    "모델이 함수 호출을 결정하면, 응답으로 일반 텍스트 대신 **함수 호출 요청**을 반환하게 됩니다. 즉, 어시스턴트는 직접 답을 주는 대신 `get_weather` 함수를 특정 인수로 호출하라는 정보를 주게 됩니다. \n",
    "아래 코드에서는 ChatCompletion API를 호출하여 이러한 과정을 실행하고, 결과를 `completion` 변수에 저장합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d9d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\":\"user\", \"content\":\"오늘 서울 날씨 어때요?\"}]\n",
    "tools = [{\n",
    "    \"type\":\"function\",\n",
    "    \"function\":{\n",
    "        \"name\":\"get_weather\",\n",
    "        \"description\":\"저장된 좌표의 현재 온도를 섭씨 단위로 구합니다\",\n",
    "        \"parameters\":{\n",
    "            \"type\":\"object\",\n",
    "            \"properties\":{\n",
    "                \"latitude\":{\"type\":\"number\"}, # 위도\n",
    "                \"longitude\":{\"type\":\"number\"} # 경도\n",
    "            }, # properties 끝\n",
    "            \"required\":[\"latitude\", \"longitude\"],\n",
    "            \"additionalProperties\" :False # 지정된 properties 이외에는 추가적인 키를 허용 안 함\n",
    "        } # parameters 끝\n",
    "    }, # function 끝\n",
    "    \"strict\":True\n",
    "}]\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    parallel_tool_calls=False # 병렬처리하지 않고 하나만 받음\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee32ec3e",
   "metadata": {},
   "source": [
    "## 5. 함수 호출 결과 처리 및 최종 답변\n",
    "\n",
    "모델이 함수 호출 요청을 반환했다면, 이제 개발자 측에서 해당 함수를 실제로 실행하고 그 결과를 어시스턴트에게 전달해야 합니다. \n",
    "우선 `completion.choices[0].message.tool_calls`를 통해 모델이 요청한 함수 호출 정보를 확인해보겠습니다. 여기에는 호출하려는 함수 이름과 전달된 인자들이 포함되어 있습니다. 우리 예시의 경우 모델은 `get_weather` 함수를 호출하도록 응답했을 것이며, 서울의 위도와 경도에 해당하는 값을 인자로 제공했을 것입니다. \n",
    "모델이 반환한 함수 호출 정보 (tool_call)를 이용해 실제 `get_weather` 함수를 실행하고, 그 결과(현재 기온)를 얻어보겠습니다. 그런 다음 이 결과를 다시 대화의 맥락에 추가하여, 어시스턴트가 최종 답변을 생성할 수 있도록 합니다. \n",
    "\n",
    "먼저, 모델 응답에 담긴 `tool_calls` 목록을 확인하고, 필요한 인자를 추출해 함수를 호출해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d1fc24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-Cmr5qLtPFxZFRTqVscjfrvVT0mqTk', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_op7mLDMVvXxLM2E1LcPF9dTH', function=Function(arguments='{\"latitude\":33.4996,\"longitude\":126.5312}', name='get_weather'), type='function')]))], created=1765759870, model='gpt-4.1-nano-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_7f8eb7d1f9', usage=CompletionUsage(completion_tokens=24, prompt_tokens=66, total_tokens=90, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion #제주 날씨어때에 대한 응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "284e33a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-Cmr8KCIG9ilw65FArXnWCWwkCB0ej', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_r2ITd0a9zAG5WFbPi6OMBwf8', function=Function(arguments='{\"latitude\":37.5665,\"longitude\":126.978}', name='get_weather'), type='function')]))], created=1765760024, model='gpt-4.1-nano-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_7f8eb7d1f9', usage=CompletionUsage(completion_tokens=23, prompt_tokens=66, total_tokens=89, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion # 서울 날씨 어때에 대한 응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e2fa735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_r2ITd0a9zAG5WFbPi6OMBwf8', function=Function(arguments='{\"latitude\":37.5665,\"longitude\":126.978}', name='get_weather'), type='function')])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "222ae737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageFunctionToolCall(id='call_r2ITd0a9zAG5WFbPi6OMBwf8', function=Function(arguments='{\"latitude\":37.5665,\"longitude\":126.978}', name='get_weather'), type='function')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llm이 자연어분석하여 \"서울\"의 좌표를 내부적으로 매핑\n",
    "completion.choices[0].message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "306a9cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.8\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "for tool_call in completion.choices[0].message.tool_calls:\n",
    "    name = tool_call.function.name\n",
    "    arg  = json.loads(tool_call.function.arguments)\n",
    "    # print(name, arg, type(arg))\n",
    "    latitude = arg.get('latitude')\n",
    "    longitude = arg.get('longitude')\n",
    "    # print(name, latitude, longitude)\n",
    "    if name == 'get_weather':\n",
    "        result = get_weather(latitude, longitude)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d269719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': '오늘 서울 날씨 어때요?'}]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8d551f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessageFunctionToolCall(id='call_r2ITd0a9zAG5WFbPi6OMBwf8', function=Function(arguments='{\"latitude\":37.5665,\"longitude\":126.978}', name='get_weather'), type='function')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f9ae779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages에 tools를 추가\n",
    "messages.append(completion.choices[0].message)\n",
    "messages.append({\n",
    "    \"role\":\"tool\",\n",
    "    \"tool_call_id\":tool_call.id,\n",
    "    \"content\":str(result) # content는 스트링이나 리스트로 \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f718c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': '오늘 서울 날씨 어때요?'},\n",
       " ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_r2ITd0a9zAG5WFbPi6OMBwf8', function=Function(arguments='{\"latitude\":37.5665,\"longitude\":126.978}', name='get_weather'), type='function')]),\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'call_r2ITd0a9zAG5WFbPi6OMBwf8',\n",
       "  'content': '-1.8'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db05f1c5",
   "metadata": {},
   "source": [
    "함수 실행 결과를 어시스턴트 대화에 추가해 보겠습니다. `messages.append(...)`를 사용하여, 먼저 어시스턴트의 함수 호출 메시지를 대화 내역에 넣고, 이어서 'tool' 역할의 메시지를 추가합니다. 이 'tool' 메시지에는 함수 호출의 `id`와 실행 결과를 문자열로 담았습니다. 이렇게 하면 OpenAI API는 해당 함수 호출에 대한 결과를 받았다고 인식하게 됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2e624a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4.1-nano\",\n",
    "    messages=messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93bcc86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오늘 서울의 날씨는 약간 쌀쌀하며 기온이 낮습니다. 외출 시 옷차림에 신경 쓰시는 것이 좋겠습니다.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7c13f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b17b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
