{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8bc20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:99% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
       "div.text_cell_render.rendered_html{font-size:20pt;}\n",
       "div.text_cell_render li, div.text_cell_render p, code{font-size:22pt; line-height:40px;}\n",
       "div.output {font-size:24pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:24pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
       "table.dataframe{font-size:24px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:99% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
    "div.text_cell_render.rendered_html{font-size:20pt;}\n",
    "div.text_cell_render li, div.text_cell_render p, code{font-size:22pt; line-height:40px;}\n",
    "div.output {font-size:24pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:24pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
    "table.dataframe{font-size:24px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd255463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a358f54",
   "metadata": {},
   "source": [
    "# OpenAI Assistants API를 활용한 서비스 구현 튜토리얼 (2025년 3월 기준)\n",
    "\n",
    "본 튜토리얼에서는 OpenAI Assistants API를 활용하여 AI 어시스턴트 기반 서비스를 개발하는 방법을 단계별로 설명합니다. 2025년 3월 기준의 OpenAI 공식 API 문서를 기반으로 최신 기능과 모범 사례를 반영했으며, Python 예제 코드를 통해 실습 형태로 진행됩니다. 이 튜토리얼은 ChatGPT 등의 언어 모델 API 사용 경험이 있고, 새로운 Assistants API 기능에 관심이 있는 개발자를 대상으로 합니다.\n",
    "\n",
    "## 1. OpenAI Assistants API 소개\n",
    "\n",
    "OpenAI Assistants API는 OpenAI의 새로운 API로, 대화형 AI 어시스턴트를 보다 쉽게 구축하고 관리할 수 있도록 설계되었습니다. 기존의 Chat Completion API가 무상태(stateless) 방식이어서 매 요청마다 대화 기록을 모두 보내야 했다면, Assistants API는 상태를 유지(stateful) 하는 대화 스레드(Thread)를 제공하여 자동으로 대화 컨텍스트를 관리합니다. 또한 함수 호출, 코드 실행, 지식 검색 등의 도구(Tools) 를 어시스턴트에 병렬로 연결할 수 있어 훨씬 강력한 코파일럿(copilot) 형태의 서비스를 구축할 수 있습니다. \n",
    "\n",
    "왜 Assistants API를 사용해야 할까요? 몇 가지 주요 장점을 정리하면 다음과 같습니다:\n",
    "\n",
    "- 대화 지속성 & 메모리: Assistants API는 대화 스레드에 메시지 내역을 지속적으로 저장하며, 컨텍스트 윈도우 제한 내에서 자동으로 요약/잘라내기를 수행합니다. 개발자는 별도의 상태 관리 로직 없이 장기간의 대화도 처리할 수 있습니다.\n",
    "\n",
    "- 다양한 도구 통합: 어시스턴트가 코드 실행(Code Interpreter), 지식 검색(File Retrieval), 함수 호출(Function Calling) 등의 도구를 직접 사용하도록 구성할 수 있습니다. 이를 통해 모델의 한계를 넘어서는 작업(예: 데이터베이스 질의, 파일 처리, 외부 API 호출 등)을 자동화할 수 있습니다.\n",
    "\n",
    "- 개인화된 지시어: 어시스턴트를 생성할 때 지시어(Instructions) 를 주입함으로써 해당 어시스턴트의 성격과 역할을 미리 정의할 수 있습니다. 예를 들어 “당신은 친절한 고객지원 봇입니다”와 같은 시스템 지시어로 어시스턴트의 톤과 도메인 지식을 설정할 수 있습니다.\n",
    "\n",
    "- 모델 기능 향상: 2023년 11월 이후 공개된 GPT-3.5/4 모델 (예: gpt-3.5-turbo-1106, gpt-4-1106-preview)은 함수 호출과 같은 고급 기능을 지원하며 Assistants API와 연동됩니다. Assistants API를 사용하면 이러한 최신 모델 기능을 간편하게 활용할 수 있습니다.\n",
    "\n",
    "- 개발 편의: OpenAI 플랫폼의 웹 인터페이스(플레이그라운드)뿐 아니라 API를 통해서도 동일한 어시스턴트를 생성/관리할 수 있습니다. 한 번 만든 어시스턴트를 재사용하거나 여러 쓰레드를 동시에 운영하는 것이 쉬워집니다. (예: 하나의 어시스턴트에 대해 다수의 사용자 대화 스레드를 관리)\n",
    "\n",
    "요약하면, Assistants API는 기존 ChatGPT API의 상태 관리 진화판으로 볼 수 있습니다. 복잡한 대화 상태 관리, 외부 도구 통합, 문서 임베딩 등 많은 부분을 OpenAI 플랫폼이 맡아주므로, 개발자는 핵심 로직 구현에 집중할 수 있습니다. 이러한 이유로, 코파일럿 스타일의 챗봇이나 자동화 에이전트를 만든다면 Assistants API가 강력한 선택지가 됩니다.\n",
    "\n",
    ">Note: Assistants API는 2025년 초 현재 베타(beta) 단계로, OpenAI가 지속적으로 기능을 개선하고 있습니다. 사용 전에 최신 문서를 확인하고, 베타 API인 만큼 일부 동작이나 요금 정책이 변경될 수 있음을 유의하세요.\n",
    "\n",
    "## 2. API 키 설정 및 환경 변수 사용\n",
    "\n",
    "OpenAI API를 사용하려면 API 키가 필요합니다. OpenAI 플랫폼의 API 키 관리 페이지에서 비밀 키를 생성할 수 있습니다. 생성된 키는 한 번만 표시되므로, 반드시 복사하여 안전한 곳에 저장하세요. 일반적으로 이 키를 소스 코드에 하드코딩하지 않고, 별도의 설정으로 관리하는 것이 좋습니다. **환경 변수(Environment Variable)**를 사용하면 API 키를 소스 코드에 노출하지 않고 관리할 수 있습니다. 개발 PC 또는 서버의 환경 변수 OPENAI_API_KEY에 키를 저장해 두면, OpenAI 라이브러리가 자동으로 이를 읽어 사용할 수 있습니다. Python 개발 환경에서는 python-dotenv 패키지를 활용해 .env 파일에 키를 저장하고 로드하는 방식이 편리합니다. \n",
    "\n",
    "다음은 API 키를 설정하고 로드하는 과정입니다:\n",
    "\n",
    "1. python-dotenv 설치: 터미널에서 pip install python-dotenv 명령으로 설치합니다 (한번만 수행).\n",
    "\n",
    "2. 환경 변수 파일 생성: 프로젝트 루트 디렉토리에 .env 파일을 만들고, 아래와 같이 OpenAI API 키를 입력합니다 (따옴표 없이 실제 키로 대체).\n",
    "\n",
    "    ```\n",
    "    OPENAI_API_KEY=sk-***********************\n",
    "    ```\n",
    "    \n",
    "3. 코드에서 로드: Python 코드에서 python-dotenv를 이용해 .env를 로드하고, os.environ을 통해 키를 불러옵니다. OpenAI 공식 Python SDK에서는 환경 변수 OPENAI_API_KEY를 자동으로 인식하므로, 명시적으로 지정하지 않아도 동작합니다. 그래도 명확성을 위해 아래와 같이 작성할 수 있습니다:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ce0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from decouple import config\n",
    "from openai import OpenAI\n",
    "import os\n",
    "# 1. client 생성\n",
    "load_dotenv(\".env\") # 기본값 \".env\"\n",
    "# api_key = os.getenv('OPENAI_API_KEY')\n",
    "# api_key = config('OPENAI_API_KEY')\n",
    "# print(api_key[:5])\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524afffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단순요청\n",
    "# response = client.chat.completions.create(\n",
    "#     model = '',\n",
    "#     # messages=[{\"role\":\"user\", \"content\":\"서울 날씨가 어떤가요?\"}]\n",
    "#     messages=\"오늘 날씨가 어떤가요?\"\n",
    "# )\n",
    "# Assistant API이용하여 (1) 대화이력을 저장 (2)파일 첨부 (3) 함수호출(ex.날씨를 반환하는 함수)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a32bc",
   "metadata": {},
   "source": [
    "## 3. 기본적인 Assistant 생성 및 메시지 보내기\n",
    "\n",
    "가장 먼저, **어시스턴트(Assistant)**를 하나 만들어보겠습니다. 어시스턴트는 대화를 수행하는 주체로, 사용자의 요청을 받아 처리하는 AI 에이전트라고 볼 수 있습니다. Assistants API에서 어시스턴트를 생성할 때는 어떤 모델을 사용할지, 어떤 지시어(Instructions) 를 가질지, 그리고 사용할 **툴(Tools)**이 무엇인지 등을 설정할 수 있습니다. 예를 들어 간단한 챗봇 어시스턴트를 만들어 사용자 질문에 답변해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdb7d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. assistant 생성 : 인공지능 캐렉터(기능 정의)\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"HelpBot\",\n",
    "    instructions=\"당신은 유능하고 친절한 도움말 어시스턴트입니다. 사용자 질문에 20자이내로 답변하세요\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # tools=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4a5df8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant ID : asst_4gBqxGrrNXDNLQiMg9XWT175\n"
     ]
    }
   ],
   "source": [
    "assistant\n",
    "print('Assistant ID :', assistant.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c0e94b",
   "metadata": {},
   "source": [
    "위 코드에서는 client.beta.assistants.create 메서드를 사용해 새로운 어시스턴트를 생성했습니다. 주요 파라미터를 살펴보면:\n",
    "\n",
    "- name: 어시스턴트의 이름을 지정합니다. 콘솔이나 리스트에서 구분하기 위한 용도이며, 모델 응답 내용에는 영향을 미치지 않습니다.\n",
    "\n",
    "- instructions: 시스템 레벨의 지시어로, 해당 어시스턴트가 모든 대화에서 따르게 될 기본 규칙이나 역할을 정의합니다. 여기서는 \"친절한 도움말 어시스턴트\"라는 성격을 부여했습니다. (이 지시어는 기존 ChatGPT의 시스템 메시지와 유사한 역할입니다.)\n",
    "\n",
    "- model: 어시스턴트가 사용할 언어 모델을 지정합니다. 최신 기능을 쓰려면 OpenAI가 Nov 2023 이후 출시한 모델(-1106가 붙은 모델명)을 권장합니다. \n",
    "\n",
    "- assistant 생성을 제공하는 모델\n",
    "    GPT-4 계열:\n",
    "    gpt-4 - 기본 GPT-4 모델\n",
    "    gpt-4-turbo - 더 빠르고 효율적인 GPT-4\n",
    "    gpt-4o - 최신 멀티모달 모델\n",
    "    gpt-4o-mini - 경량화된 GPT-4o\n",
    "\n",
    "    GPT-3.5 계열:\n",
    "    gpt-3.5-turbo - 빠르고 효율적인 모델(추천)\n",
    "\n",
    "    기타:\n",
    "    dall-e-3 - 이미지 생성용\n",
    "    whisper-1 - 음성 인식용\n",
    "    tts-1, tts-1-hd - 텍스트 음성 변환용\n",
    "\n",
    "\n",
    "- tools: 어시스턴트에 활성화할 도구 목록입니다. 기본적인 Q&A 챗봇에서는 특별한 툴이 필요 없으므로 비워두었습니다. (tools=[] 또는 생략) 나중에 코드 인터프리터나 함수 호출 등을 사용하게 될 경우 이 필드를 설정합니다.\n",
    "\n",
    "어시스턴트가 성공적으로 생성되면 고유 ID (assistant.id)가 반환됩니다. 이 ID는 이후 대화 스레드에서 어떤 어시스턴트를 사용할지 지정할 때 필요하므로 저장해둡니다. (참고로, client.beta.assistants.list()를 호출하면 계정 내 모든 어시스턴트 목록을 확인할 수 있습니다.) \n",
    "\n",
    "이제 이 어시스턴트와 대화를 시작해보겠습니다. 대화를 하기 위해서는 **스레드(Thread)**를 생성해야 합니다. 스레드는 개별적인 대화 세션을 나타내며, 사용자와 어시스턴트 간의 메시지(Message) 목록을 포함합니다. 하나의 어시스턴트는 여러 개의 스레드를 가질 수 있는데, 예를 들어 같은 어시스턴트를 여러 사용자가 동시에 이용하면 각 사용자별로 별도 스레드가 생깁니다. \n",
    "\n",
    "스레드를 만들고, 그 안에 사용자 메시지를 추가한 뒤, 어시스턴트의 답변을 요청하는 일련의 과정을 코드로 수행해봅시다:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9961b2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_PxFPbtni1seEIIVjPWB4Eqbj', assistant_id='asst_4gBqxGrrNXDNLQiMg9XWT175', cancelled_at=None, completed_at=1765507817, created_at=1765507814, expires_at=None, failed_at=None, incomplete_details=None, instructions='당신은 유능하고 친절한 도움말 어시스턴트입니다. 사용자 질문에 20자이내로 답변하세요', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o-mini', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=1765507816, status='completed', thread_id='thread_pTXrND1lYj73DnpNK5NxEq5i', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=14, prompt_tokens=69, total_tokens=83, prompt_token_details={'cached_tokens': 0}, completion_tokens_details={'reasoning_tokens': 0}), temperature=1.0, top_p=1.0, tool_resources={}, reasoning_effort=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 새로운 대화 thread 생성 : 기억을 담당\n",
    "thread = client.beta.threads.create()\n",
    "# thread\n",
    "# 4. 스레드에 사용자 메세지 추가\n",
    "# user_message = \n",
    "client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"서울 날씨 몇도까지 떨어져요?\"\n",
    ")\n",
    "# user_message\n",
    "# 5. 어시스턴트에게 답변 생성 요청 (과금)\n",
    "# run = \n",
    "client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")\n",
    "#run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb44c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. OpenAI API 요청 후, 스레드의 모든 메세지 불러오기\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65e47f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant(2025-12-12 11:50:17) : 최저 기온은 대략 0도입니다.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# messages.data[0]\n",
    "reply = messages.data[0].content[0].text.value\n",
    "role = messages.data[0].role\n",
    "replyDate = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(messages.data[0].created_at))\n",
    "print(f\"{role}({replyDate}) : {reply}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "200e2d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Message(id='msg_DPNw0aNprB9BjkeZ0WRiNCOZ', assistant_id='asst_4gBqxGrrNXDNLQiMg9XWT175', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='최저 기온은 대략 0도입니다.'), type='text')], created_at=1765507817, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_PxFPbtni1seEIIVjPWB4Eqbj', status=None, thread_id='thread_pTXrND1lYj73DnpNK5NxEq5i'),\n",
       " Message(id='msg_qc0wVnLNImk8btZHwqsEoKp1', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='서울 날씨 몇도까지 떨어져요?'), type='text')], created_at=1765507812, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_pTXrND1lYj73DnpNK5NxEq5i')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-1 메세지를 시간 순서대로 정렬\n",
    "messages.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a49c187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['김', '박', '홍']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스칼라 데이터 리스트 sort\n",
    "students = ['김', '홍', '박']\n",
    "students.sort()\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "577e01af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1765509357.7477725"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time() # 1970.1.1 ~ 지금까지 초수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1deff443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun = lambda student : student['score']\n",
    "fun({'name':'홍', 'score':90})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cae41a75",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '김', 'create_at': 1765423321.859713, 'score': 90},\n",
       " {'name': '박', 'create_at': 1765509721.859713, 'score': 20},\n",
       " {'name': '홍', 'create_at': 1765596121.859713, 'score': 60}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 딕셔너리 리스트 sort\n",
    "students = [\n",
    "    {'name':'홍', 'create_at':time.time()+60*60*24, \"score\":60},\n",
    "    {'name':'김', 'create_at':time.time()-60*60*24, \"score\":90},\n",
    "    {'name':'박', 'create_at':time.time(), \"score\":20},\n",
    "]\n",
    "sorted_students = sorted(students,\n",
    "                        key=lambda student : student['create_at'],\n",
    "                        #reverse=True\n",
    "                        )\n",
    "sorted_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "571ff908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user (2025-12-12 11:50:12) : 서울 날씨 몇도까지 떨어져요?\n",
      "assistant (2025-12-12 11:50:17) : 최저 기온은 대략 0도입니다.\n"
     ]
    }
   ],
   "source": [
    "# 6-1 메세지를 시간 순서대로 정렬\n",
    "sorted_messages = sorted(messages.data,\n",
    "                    key=lambda msg : msg.created_at\n",
    ")\n",
    "# 7. 답변들 history\n",
    "for msg in sorted_messages:\n",
    "    #print(msg)\n",
    "    content = msg.content[0].text.value\n",
    "    role = msg.role\n",
    "    dateStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(msg.created_at))\n",
    "    print(\"{} ({}) : {}\".format(role, dateStr, content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa5894b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3411323b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777da86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb2f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e415789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ede295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
