{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0abaf475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:99% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
       "div.text_cell_render.rendered_html{font-size:20pt;}\n",
       "div.text_cell_render ul li, div.text_cell_render ol li p, code{font-size:22pt; line-height:30px;}\n",
       "div.output {font-size:24pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:24pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
       "table.dataframe{font-size:24px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:99% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
    "div.text_cell_render.rendered_html{font-size:20pt;}\n",
    "div.text_cell_render ul li, div.text_cell_render ol li p, code{font-size:22pt; line-height:30px;}\n",
    "div.output {font-size:24pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:24pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
    "table.dataframe{font-size:24px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0866da",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">ch4_RNN(RecurrentNeuralNetwork;순환신경망)</span>\n",
    "- 데이터의 순서가 중요하거나, 시계열 데이터일 경우\n",
    "- 활용분야 : 번역, 음성인식, 주가예측, 농수산물가격예측\n",
    "#  1. 문맥을 이용하여 모델만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62de5201",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"경마장에 있는 말이 뛰고 있다\n",
    "그의 말이 법이다\n",
    "가는 말이 고와야 오는 말이 곱다\"\"\"\n",
    "text1 = \"겨울이 오는 날\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8ae8312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 4, 1, 5, 6, 7, 1, 8, 9, 1, 10, 2, 1, 11], [12, 2, 13]]\n",
      "{'말이': 1, '오는': 2, '경마장에': 3, '있는': 4, '뛰고': 5, '있다': 6, '그의': 7, '법이다': 8, '가는': 9, '고와야': 10, '곱다': 11, '겨울이': 12, '날': 13}\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.text import Tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts([text, text1])\n",
    "encoded = t.texts_to_sequences([text, text1])\n",
    "print(encoded)\n",
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd159689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.texts_to_sequences(['경마장에 있는 말이 뛴다'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c97a43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"경마장에 있는 말이 뛰고 있다\n",
    "그의 말이 법이다\n",
    "가는 말이 고와야 오는 말이 곱다\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e2b5e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 1, 4, 5, 6, 1, 7, 8, 1, 9, 10, 1, 11]\n",
      "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts([text])\n",
    "encoded = t.texts_to_sequences([text])[0]\n",
    "print(encoded)\n",
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39e58c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말이 1\n",
      "경마장에 2\n",
      "있는 3\n",
      "뛰고 4\n",
      "있다 5\n",
      "그의 6\n",
      "법이다 7\n",
      "가는 8\n",
      "고와야 9\n",
      "오는 10\n",
      "곱다 11\n"
     ]
    }
   ],
   "source": [
    "for key, value in t.word_index.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9eb8ef2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문장: 경마장에 있는 말이 뛰고 있다 , encoded된 문장: [2, 3, 1, 4, 5]\n",
      "원문장: 그의 말이 법이다 , encoded된 문장: [6, 1, 7]\n",
      "원문장: 가는 말이 고와야 오는 말이 곱다 , encoded된 문장: [8, 1, 9, 10, 1, 11]\n",
      "sequences와 해석\n",
      "2:경마장에 3:있는 \n",
      "2:경마장에 3:있는 1:말이 \n",
      "2:경마장에 3:있는 1:말이 4:뛰고 \n",
      "2:경마장에 3:있는 1:말이 4:뛰고 5:있다 \n",
      "3:있는 1:말이 \n",
      "3:있는 1:말이 4:뛰고 \n",
      "3:있는 1:말이 4:뛰고 5:있다 \n",
      "1:말이 4:뛰고 \n",
      "1:말이 4:뛰고 5:있다 \n",
      "4:뛰고 5:있다 \n",
      "6:그의 1:말이 \n",
      "6:그의 1:말이 7:법이다 \n",
      "1:말이 7:법이다 \n",
      "8:가는 1:말이 \n",
      "8:가는 1:말이 9:고와야 \n",
      "8:가는 1:말이 9:고와야 10:오는 \n",
      "8:가는 1:말이 9:고와야 10:오는 1:말이 \n",
      "8:가는 1:말이 9:고와야 10:오는 1:말이 11:곱다 \n",
      "1:말이 9:고와야 \n",
      "1:말이 9:고와야 10:오는 \n",
      "1:말이 9:고와야 10:오는 1:말이 \n",
      "1:말이 9:고와야 10:오는 1:말이 11:곱다 \n",
      "9:고와야 10:오는 \n",
      "9:고와야 10:오는 1:말이 \n",
      "9:고와야 10:오는 1:말이 11:곱다 \n",
      "10:오는 1:말이 \n",
      "10:오는 1:말이 11:곱다 \n",
      "1:말이 11:곱다 \n"
     ]
    }
   ],
   "source": [
    "# text를 학습시키기 위해, ['경마장에 있는'(2,3), '경마장에 있는 말이'(2,3,1), .....]\n",
    "sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "    print('원문장:', line, ', encoded된 문장:',encoded)\n",
    "    for i in range(0, len(encoded)-1): # 시작index\n",
    "        for j in range(i+2, len(encoded)+1): # 끝나는 index+1\n",
    "            sequences.append(encoded[i:j])\n",
    "#sequences, len(sequences)\n",
    "print('sequences와 해석')\n",
    "for sequence in sequences:\n",
    "    # print(sequence)\n",
    "    for word_seq in sequence:\n",
    "        for key, value in t.word_index.items():\n",
    "            if word_seq==value:\n",
    "                print(\"{}:{}\".format(word_seq, key), end=' ')\n",
    "                break\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "116ec870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3],\n",
       " [2, 3, 1],\n",
       " [2, 3, 1, 4],\n",
       " [2, 3, 1, 4, 5],\n",
       " [3, 1],\n",
       " [3, 1, 4],\n",
       " [3, 1, 4, 5],\n",
       " [1, 4],\n",
       " [1, 4, 5],\n",
       " [4, 5],\n",
       " [6, 1],\n",
       " [6, 1, 7],\n",
       " [1, 7],\n",
       " [8, 1],\n",
       " [8, 1, 9],\n",
       " [8, 1, 9, 10],\n",
       " [8, 1, 9, 10, 1],\n",
       " [8, 1, 9, 10, 1, 11],\n",
       " [1, 9],\n",
       " [1, 9, 10],\n",
       " [1, 9, 10, 1],\n",
       " [1, 9, 10, 1, 11],\n",
       " [9, 10],\n",
       " [9, 10, 1],\n",
       " [9, 10, 1, 11],\n",
       " [10, 1],\n",
       " [10, 1, 11],\n",
       " [1, 11]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3912dd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_len = max([len(sequence) for sequence in sequences])\n",
    "my_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d7e9a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " (28, 6),\n",
       " array([[ 0,  0,  0,  0,  2,  3],\n",
       "        [ 0,  0,  0,  2,  3,  1],\n",
       "        [ 0,  0,  2,  3,  1,  4],\n",
       "        [ 0,  2,  3,  1,  4,  5],\n",
       "        [ 0,  0,  0,  0,  3,  1],\n",
       "        [ 0,  0,  0,  3,  1,  4],\n",
       "        [ 0,  0,  3,  1,  4,  5],\n",
       "        [ 0,  0,  0,  0,  1,  4],\n",
       "        [ 0,  0,  0,  1,  4,  5],\n",
       "        [ 0,  0,  0,  0,  4,  5],\n",
       "        [ 0,  0,  0,  0,  6,  1],\n",
       "        [ 0,  0,  0,  6,  1,  7],\n",
       "        [ 0,  0,  0,  0,  1,  7],\n",
       "        [ 0,  0,  0,  0,  8,  1],\n",
       "        [ 0,  0,  0,  8,  1,  9],\n",
       "        [ 0,  0,  8,  1,  9, 10],\n",
       "        [ 0,  8,  1,  9, 10,  1],\n",
       "        [ 8,  1,  9, 10,  1, 11],\n",
       "        [ 0,  0,  0,  0,  1,  9],\n",
       "        [ 0,  0,  0,  1,  9, 10],\n",
       "        [ 0,  0,  1,  9, 10,  1],\n",
       "        [ 0,  1,  9, 10,  1, 11],\n",
       "        [ 0,  0,  0,  0,  9, 10],\n",
       "        [ 0,  0,  0,  9, 10,  1],\n",
       "        [ 0,  0,  9, 10,  1, 11],\n",
       "        [ 0,  0,  0,  0, 10,  1],\n",
       "        [ 0,  0,  0, 10,  1, 11],\n",
       "        [ 0,  0,  0,  0,  1, 11]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequences를 훈련가능하도록 6(my_len)개열로 조정\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_sequences = pad_sequences(sequences=sequences,\n",
    "                                maxlen=my_len,\n",
    "                                #padding='post' \n",
    "                                padding='pre') # 상황에 맞게 특별한 규칙은 없음\n",
    "type(padded_sequences), padded_sequences.shape, padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89fcb2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 5), (28,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 독립변수(X)와 타겟변수(y)로 분리\n",
    "X = padded_sequences[:, :-1]\n",
    "y = padded_sequences[:, -1]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "833c42bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 갯수\n",
    "vocab_size = len(t.word_index)\n",
    "# X를 임베딩작업을 할 때 input_dim\n",
    "input_dim = vocab_size + 1\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "779a4723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타겟변수(y)의 원핫인코딩\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "Y = to_categorical(y, vocab_size+1)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab960b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 5), (28, 12), 11)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38ca0023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 5, 10)             120       \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 32)                1376      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12)                396       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,892\n",
      "Trainable params: 1,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "# 모델 생성하기\n",
    "model = Sequential()\n",
    "# 원핫인코딩한 희소행렬을 임베딩 벡터로 변환(X=[0,8,1,9,10])\n",
    "model.add(Embedding(input_dim=vocab_size+1,  # 임베딩층의 입력(원핫인코딩 dim)\n",
    "                    output_dim=10,           # 임베딩층의 출력\n",
    "                    input_length=X.shape[1])) # 입력 데이터 길이\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "model.summary()\n",
    "# 두번째 layer의 파라미터 1376 = (10+32)*32 + 32(bias) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9720a45a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c23ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9a6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e06a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a48fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee790a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22d3156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b01766e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db528d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp(ipykernel)",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
